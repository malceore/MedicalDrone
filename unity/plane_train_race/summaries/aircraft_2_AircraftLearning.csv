Steps,Policy/Entropy,Environment/Lesson,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Is Training
32000,2.3826637,0.0,36.17169373549884,6.38865,-0.8259737426187934,-0.8259737426187934,30.806648,0.021110173,0.00029987693,1.0
64000,2.372197,0.0,46.76268656716418,5.0875688,-0.7099426623155821,-0.7099426623155821,15.377129,0.019870006,0.00029969227,1.0
96000,2.3434298,0.0,53.08121827411168,4.481968,-0.6273136653522953,-0.6273136653522953,11.120152,0.018159993,0.00029950778,1.0
128000,2.3440828,0.0,58.718283582089555,3.845268,-0.5323906185578055,-0.5323906185578055,6.864868,0.02147134,0.00029932286,1.0
160000,2.338035,0.0,62.27865612648221,3.5437753,-0.4906718743589556,-0.4906718743589556,5.2957234,0.0139856655,0.00029913802,1.0
