Steps,Policy/Entropy,Environment/Lesson,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Is Training
32000,2.1554346,0.0,29.154280338664158,-28.548338,-0.8324574310115053,-0.8324574310115053,357.70914,0.022595042,0.00029987682,1.0
64000,2.251704,0.0,22.960269865067467,-18.651892,-0.9261380809134451,-0.9261380809134451,202.6051,0.019378426,0.0002996922,1.0
96000,2.2936225,0.0,20.89131920710868,-8.463707,-0.96438523758297,-0.96438523758297,50.534786,0.014333215,0.00029950775,1.0
128000,2.2918234,0.0,19.988845144356954,-5.061604,-0.9832030222641202,-0.9832030222641202,17.02592,0.014550377,0.00029932332,1.0
160000,2.3034801,0.0,20.106270627062706,-3.7094705,-0.9873794138628265,-0.9873794138628265,8.475039,0.019094616,0.0002991389,1.0
192000,2.3406427,0.0,18.68450184501845,-2.3106432,-0.9989922600368732,-0.9989922600368732,4.1776457,0.019572852,0.0002989545,1.0
224000,2.3767638,0.0,17.310246136233545,-1.6627483,-1.0016004646854804,-1.0016004646854804,1.8638008,0.021031404,0.00029877,1.0
256000,2.3514884,0.0,17.565797101449274,-1.3837799,-1.002222271863965,-1.002222271863965,1.1511508,0.015379718,0.00029858557,1.0
