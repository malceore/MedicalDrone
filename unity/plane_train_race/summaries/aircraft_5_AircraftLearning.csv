Steps,Policy/Entropy,Environment/Lesson,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Is Training
32000,2.3450265,0.0,50.138977635782744,-5.7960687,-0.8947478447437286,-0.8947478447437286,48.172485,0.035329238,0.00029987688,1.0
64000,2.3065214,0.0,49.70839936608558,-4.809454,-0.9203515040043228,-0.9203515040043228,12.189556,0.017559487,0.0002996924,1.0
96000,2.2549984,0.0,49.319182389937104,-3.853243,-0.9107547098969888,-0.9107547098969888,4.8673344,0.014966732,0.00029950778,1.0
128000,2.245849,0.0,44.87965616045845,-2.6472917,-0.9057787931751043,-0.9057787931751043,1.7362007,0.016376795,0.00029932326,1.0
160000,2.2053792,0.0,40.70404172099087,-1.8943732,-0.905704825572582,-0.905704825572582,0.69841504,0.016161988,0.00029913863,1.0
192000,2.2252302,0.0,29.599043062200955,-1.3864342,-0.9331064147812328,-0.9331064147812328,0.46656322,0.017008718,0.00029895385,1.0
224000,2.2521813,0.0,22.044636429085674,-1.1069129,-0.9621719271266435,-0.9621719271266435,0.2349522,0.016757656,0.00029876936,1.0
256000,2.2119823,0.0,22.45054945054945,-1.0339173,-0.9534550983390528,-0.9534550983390528,0.15924555,0.018033668,0.00029858493,1.0
288000,2.2094822,0.0,25.3676834295136,-0.90020114,-0.9385821949521668,-0.9385821949521668,0.1104071,0.019405242,0.00029833894,1.0
320000,2.1915042,0.0,30.395098039215686,-0.7915179,-0.9123149051970126,-0.9123149051970126,0.086013116,0.014230521,0.00029815454,1.0
352000,2.125686,0.0,40.62418725617685,-0.7063644,-0.8552733392724755,-0.8552733392724755,0.07837831,0.017281748,0.00029797002,1.0
